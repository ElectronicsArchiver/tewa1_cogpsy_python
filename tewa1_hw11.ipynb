{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7836b7e4-afb3-4af3-9c89-a09b94862926",
   "metadata": {
    "id": "aAmuxCstDaa3"
   },
   "source": [
    "homework 11\n",
    "===\n",
    "due: June 15 2022\n",
    "\n",
    "authors: pegler, prüwasser, scheftner\n",
    "\n",
    "---\n",
    "Read chapter 1-2 of Bayesian models of perception and action.\n",
    "\n",
    "https://www.cns.nyu.edu/malab/static/files/Bayesian_models_of_perception_and_action_v3.pdf\n",
    "\n",
    "Choose 6 problems from the end of the chapter, for both chapters, and submit the solution as text here.\n",
    "\n",
    "No need to write long explanations, try to be brief!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef562f40-8684-43f5-963b-cffc40e56d4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chapter 1\n",
    "\n",
    "### Summary\n",
    "In this chapter, we have introduced the concept that perception is inherently probabilistic, and as\n",
    "such optimally characterized as a process of Bayesian inference. Regarding Bayesian inference, we\n",
    "have learned the following:\n",
    "\n",
    "* Conditional probabilities such as $p(A | B)$ represents the probability of $A$ given $B$. In Bayesian\n",
    "perceptual inference, $A$ and $B$ typically represent a world state and an observation.\n",
    "* The likelihood function, $p(observation | world state)$, captures the information content of the\n",
    "sensory observation, relevant to distinguishing one world state from another.\n",
    "* <mark>The flatter the likelihood function, the less we learn from our senses</mark>. If the likelihood\n",
    "function is perfectly flat, then the observer has learned nothing from the observation.\n",
    "* In some cases, such as the “Is that my friend?” example, the likelihood changes over time.\n",
    "* <mark>The prior distribution over world states, $p(world state)$, summarizes the information content\n",
    "of our past observations</mark>, the background knowledge we have about the world. Perception\n",
    "is not based entirely on sensory observation, but also on expectation grounded in previous\n",
    "experience.\n",
    "* <mark>Flatter prior distributions mean we know less</mark> about the potential states of the world.\n",
    "* Bayes’ rule calculates the posterior probability of each hypothesized world state, $p(world state | observation)$,\n",
    "from the likelihoods and prior probabilities of the world states.\n",
    "* The procedures of Bayesian inference apply equally to situations in which the hypothesized\n",
    "world states are <mark>discrete</mark> or in which they are <mark>continuous</mark>.\n",
    "* Perceptual situations, whether in vision, audition, or other senses, are subject to various\n",
    "levels of <mark>uncertainty</mark>.\n",
    "* Speech perception is fraught with phonetic and syntactic ambiguity, frequently giving rise to\n",
    "flat likelihood functions. The combination of priors and likelihoods can cause misinterpretations such as mondegreens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6f6c0-434d-44a0-8226-c0a585036f17",
   "metadata": {},
   "source": [
    "### Problem 1.2 Why is it that we identify ourselves ...\n",
    "... at the very beginning of a phone conversation,\n",
    "even to people we already know, but we do not do this when we meet in person? Express your\n",
    "answer within the framework of Bayesian perceptual inference.\n",
    "\n",
    "**We know that in phone calls perception is limited to the auditory system and the quality of sensory data could be further limited by a bad phone connection. This potential noisiness we can counteract by telling the other person our name to reduce uncertainty and widen the likelihood function. When we meet someone in person we have much more and less ambigious sensory data at hand. From afar it might be still ambigious, but once we meet and see the other person from 2 or 3 meter distance we can be very certain that the other person recognizes us.**\n",
    "\n",
    "&\n",
    "\n",
    "**Person can fungate as prior and therefor influence perceived likelihood. Identifying oneself sets ankers for selection of priors (contexts), which will even the way of understanding correctly what a person might have said (likelihood) and therefor perceiving correctly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31317b8b-d35c-4930-90a7-0bd4ba944695",
   "metadata": {},
   "source": [
    "### Problem 1.4 To explore how a noisy environment ...\n",
    "...engenders uncertainty, consider the word “lunch.” Suppose that you see this word written (or hear it spoken), with the letter “l” blocked out (making it unknown): _unch (e.g., by ambient auditory noise). List all source words that are compatible with what you see. Now consider the case in which both the l and the n are blocked: _u_ch. In terms of conditional probabilities relevant to perception, what is the effect of blocking out the l, n, and both?\n",
    "\n",
    "**Bunch  \n",
    "Munch  \n",
    "Hunch (Vorahnung)  \n",
    "Punch  \n",
    "Runch (Ackerrettich)**\n",
    "\n",
    "**Conditional probabilities form transitions from sensation to perception. Blocking out certain letters transforms the sensation which can alter the perception. In detail, different world states are compared, which are subjects in likelihood functions helping to perceive the letters by interpreting their potential meaning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96270dab-60b5-4197-8157-529ef633feb7",
   "metadata": {},
   "source": [
    "### Problem 1.9 The Easter bunny in October\n",
    "\n",
    "“Whereas on Easter the drawing was significantly more often recognized as a bunny, in October it was considered a bird by most subjects.”\n",
    "To solve this mystery applying Bayes’ rule, the prior mindset  combined with  estimated likelihood of observing a certain image  influence what is perceived. \n",
    "\n",
    "**In October, events, objects and animals (like ducks and duck roasts) related to autumn are easily accessible. This portrays a different prior and according likelihood than in April, when Easter is usually  happening making Easter bunnies more prominent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260fcab-75f4-40af-967c-7057ba8d5f4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Problem 1.11 Give three daily-life examples ...\n",
    "... (perceptual or cognitive) in which you tried to infer a world state from incomplete or imperfect information. For each example, specify the observation(s), the world state of interest, and the source(s) of uncertainty\n",
    "\n",
    "**I have two flatmates, A. and M. One morning I woke up noticing one of them lying next to me (observation). I thought oh yeah that must be M., because she likes to sleep next to me (inferred world state) without investigating any further(source of uncertainty). I went on with  my morning routine only to be surprised that A. and not M. came out of my room. \n",
    "I dog-sitted the other day and every time there was a noise (observation) on the other side of the closed apartment door (source of uncertainty) the dog started barking because it expected danger or threat (inferred world state).\n",
    "When I come home, I can see the bathroom window from outside the apartment. If there is light (observation) I assume that my flatmate is home (inferred world state) without me having talked to or seen her (source of uncertainty).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa01bab2-8f28-4119-9984-92addbc0e7b7",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b9774-2d8e-4b42-8630-0f52f3054650",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4a7ad-a7eb-4ed4-a933-643853ebb52f",
   "metadata": {},
   "source": [
    "## Chapter 2\n",
    "\n",
    "### Summary\n",
    "In this chapter, we have introduced the precise formulation of Bayes’ rule and applied it to a\n",
    "range of discrete estimation problems. We have seen how Bayes’ rule makes concrete, meaningful\n",
    "statements about probabilities possible. Regarding the use of Bayes’ rule, we have learned the\n",
    "following:\n",
    "* Bayesian modeling starts with a model of the statistical structure of the world and the\n",
    "observations: the <mark>generative model</mark>.\n",
    "* Conditional probabilities are not symmetrical. In general, $p(A|B) \\ne p(B|A)$.\n",
    "* Bayes’ rule calculates the probabilities of hypotheses conditioned on the observation – the\n",
    "<mark>posterior probabilities, $p(H|obs)$</mark> – from the probabilities of the observation conditioned on\n",
    "the hypotheses – the likelihoods, $p(obs|H)$ – and the prior probabilities, $p(H)$.\n",
    "* $p(obs)$ in Bayes’ rule normalizes the probability and can be rewritten as <mark>$p(obs) = ∑H p(obs|H)p(H)$</mark>.\n",
    "* <mark>Priors do not always play the main role</mark> in Bayesian models. In some problems, such as the\n",
    "Gestalt example, the prior is relatively unimportant and the likelihood dominates.\n",
    "* In some scenarios, priors and/or likelihoods may change over time.\n",
    "* Bayesian inference is a component of deriving the optimal strategy in any inference task.\n",
    "However, not all Bayesian inference is optimal.\n",
    "* Finding evidence for (near-)optimal behavior does not necessarily mean that the components\n",
    "of the Bayesian model are internally represented in the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4268b-757f-46be-a2e2-c43ba15f3895",
   "metadata": {},
   "source": [
    "### Problem 2.1 Think of three daily-life examples ...\n",
    "... of random variables $A$ and $B$ for which intuitively, $p(A|B) \\ne p(B|A)$. In each case, state which probability is greater, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81805a-5ca9-4850-9af4-4525405619fc",
   "metadata": {},
   "source": [
    "1) **Pitbull-type dogs are not amongst the most popular dogs in Vienna, but there are certain districts in which chances are higher that a random dog that you see on the street is a Pitbull. Let's consider the 12th district, Meidling: Though it is one of the districts with the lowest dog population per resident ($p(Dog)$ is low), if you happen to see a dog in this district, the probability for \"Pitbull\" given the observation \"Dog\" ($p(Pitbull | Dog)$) is the highest among all districts in Vienna. What is the probability, that you see this random dog on the street given it is a pitbull type ($p(Dog | Pitbull)$)? It is low, even lower than $p(Dog)$ since Pitbulls are a subtype of Dog.**\n",
    "\n",
    "2)  ...\n",
    "\n",
    "\n",
    "3)  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce957e-616c-4506-a3f6-5bf290400b03",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e98ce4-5c48-4744-94dd-6570fb496f14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6f7ac-9661-45ec-9259-56dc75a6574b",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab4196-3946-47c2-8e0f-322a2c900155",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a2ff7-57ad-48c8-ba10-fa2b2dad119f",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b462f-d9d5-4335-b7d7-3f7593d63f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
